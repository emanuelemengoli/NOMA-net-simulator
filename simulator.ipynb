{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-1.26.4-cp312-cp312-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-macosx_10_9_x86_64.whl (20.3 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.26.4\n",
      "numpy has been installed.\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.2-cp312-cp312-macosx_10_9_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Using cached pandas-2.2.2-cp312-cp312-macosx_10_9_x86_64.whl (12.5 MB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n",
      "pandas has been installed.\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.9.0-cp312-cp312-macosx_10_12_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.2.1-cp312-cp312-macosx_10_9_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.52.1-cp312-cp312-macosx_10_9_universal2.whl.metadata (160 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.9/160.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.5-cp312-cp312-macosx_10_9_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (24.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-10.3.0-cp312-cp312-macosx_10_10_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Using cached matplotlib-3.9.0-cp312-cp312-macosx_10_12_x86_64.whl (7.9 MB)\n",
      "Using cached contourpy-1.2.1-cp312-cp312-macosx_10_9_x86_64.whl (263 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.52.1-cp312-cp312-macosx_10_9_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached kiwisolver-1.4.5-cp312-cp312-macosx_10_9_x86_64.whl (67 kB)\n",
      "Using cached pillow-10.3.0-cp312-cp312-macosx_10_10_x86_64.whl (3.5 MB)\n",
      "Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.52.1 kiwisolver-1.4.5 matplotlib-3.9.0 pillow-10.3.0 pyparsing-3.1.2\n",
      "matplotlib has been installed.\n",
      "Collecting geopy\n",
      "  Using cached geopy-2.4.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting geographiclib<3,>=1.52 (from geopy)\n",
      "  Using cached geographiclib-2.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Using cached geopy-2.4.1-py3-none-any.whl (125 kB)\n",
      "Using cached geographiclib-2.0-py3-none-any.whl (40 kB)\n",
      "Installing collected packages: geographiclib, geopy\n",
      "Successfully installed geographiclib-2.0 geopy-2.4.1\n",
      "geopy has been installed.\n",
      "Collecting folium\n",
      "  Using cached folium-0.16.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting branca>=0.6.0 (from folium)\n",
      "  Using cached branca-0.7.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jinja2>=2.9 (from folium)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from folium) (1.26.4)\n",
      "Collecting requests (from folium)\n",
      "  Using cached requests-2.32.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting xyzservices (from folium)\n",
      "  Using cached xyzservices-2024.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2>=2.9->folium)\n",
      "  Using cached MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->folium)\n",
      "  Using cached charset_normalizer-3.3.2-cp312-cp312-macosx_10_9_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->folium)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->folium)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->folium)\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Using cached folium-0.16.0-py2.py3-none-any.whl (100 kB)\n",
      "Using cached branca-0.7.2-py3-none-any.whl (25 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached requests-2.32.2-py3-none-any.whl (63 kB)\n",
      "Using cached xyzservices-2024.4.0-py3-none-any.whl (81 kB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp312-cp312-macosx_10_9_x86_64.whl (122 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_x86_64.whl (14 kB)\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Installing collected packages: xyzservices, urllib3, MarkupSafe, idna, charset-normalizer, certifi, requests, jinja2, branca, folium\n",
      "Successfully installed MarkupSafe-2.1.5 branca-0.7.2 certifi-2024.2.2 charset-normalizer-3.3.2 folium-0.16.0 idna-3.7 jinja2-3.1.4 requests-2.32.2 urllib3-2.2.1 xyzservices-2024.4.0\n",
      "folium has been installed.\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.5.0-cp312-cp312-macosx_10_9_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.13.1-cp312-cp312-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.5.0-cp312-cp312-macosx_10_9_x86_64.whl (12.1 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached scipy-1.13.1-cp312-cp312-macosx_10_9_x86_64.whl (39.4 MB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.0 scipy-1.13.1 threadpoolctl-3.5.0\n",
      "scikit-learn has been installed.\n",
      "Collecting simpy\n",
      "  Using cached simpy-4.1.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Using cached simpy-4.1.1-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: simpy\n",
      "Successfully installed simpy-4.1.1\n",
      "simpy has been installed.\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.66.4\n",
      "tqdm has been installed.\n",
      "Collecting imageio\n",
      "  Using cached imageio-2.34.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from imageio) (1.26.4)\n",
      "Requirement already satisfied: pillow>=8.3.2 in ./.venv/lib/python3.12/site-packages (from imageio) (10.3.0)\n",
      "Using cached imageio-2.34.1-py3-none-any.whl (313 kB)\n",
      "Installing collected packages: imageio\n",
      "Successfully installed imageio-2.34.1\n",
      "imageio has been installed.\n",
      "Collecting nbformat\n",
      "  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat)\n",
      "  Using cached fastjsonschema-2.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting jsonschema>=2.6 (from nbformat)\n",
      "  Using cached jsonschema-4.22.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.12/site-packages (from nbformat) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in ./.venv/lib/python3.12/site-packages (from nbformat) (5.14.3)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=2.6->nbformat)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=2.6->nbformat)\n",
      "  Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=2.6->nbformat)\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=2.6->nbformat)\n",
      "  Using cached rpds_py-0.18.1-cp312-cp312-macosx_10_12_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.2.2)\n",
      "Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Using cached fastjsonschema-2.19.1-py3-none-any.whl (23 kB)\n",
      "Using cached jsonschema-4.22.0-py3-none-any.whl (88 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Using cached referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Using cached rpds_py-0.18.1-cp312-cp312-macosx_10_12_x86_64.whl (329 kB)\n",
      "Installing collected packages: fastjsonschema, rpds-py, attrs, referencing, jsonschema-specifications, jsonschema, nbformat\n",
      "Successfully installed attrs-23.2.0 fastjsonschema-2.19.1 jsonschema-4.22.0 jsonschema-specifications-2023.12.1 nbformat-5.10.4 referencing-0.35.1 rpds-py-0.18.1\n",
      "nbformat has been installed.\n",
      "Collecting geopandas\n",
      "  Using cached geopandas-0.14.4-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting fiona>=1.8.21 (from geopandas)\n",
      "  Using cached fiona-1.9.6-cp312-cp312-macosx_10_15_x86_64.whl.metadata (50 kB)\n",
      "Requirement already satisfied: numpy>=1.22 in ./.venv/lib/python3.12/site-packages (from geopandas) (1.26.4)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from geopandas) (24.0)\n",
      "Requirement already satisfied: pandas>=1.4.0 in ./.venv/lib/python3.12/site-packages (from geopandas) (2.2.2)\n",
      "Collecting pyproj>=3.3.0 (from geopandas)\n",
      "  Using cached pyproj-3.6.1-cp312-cp312-macosx_10_9_x86_64.whl.metadata (31 kB)\n",
      "Collecting shapely>=1.8.0 (from geopandas)\n",
      "  Using cached shapely-2.0.4-cp312-cp312-macosx_10_9_x86_64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in ./.venv/lib/python3.12/site-packages (from fiona>=1.8.21->geopandas) (23.2.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from fiona>=1.8.21->geopandas) (2024.2.2)\n",
      "Collecting click~=8.0 (from fiona>=1.8.21->geopandas)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting click-plugins>=1.0 (from fiona>=1.8.21->geopandas)\n",
      "  Using cached click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting cligj>=0.5 (from fiona>=1.8.21->geopandas)\n",
      "  Using cached cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.12/site-packages (from fiona>=1.8.21->geopandas) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2024.1)\n",
      "Using cached geopandas-0.14.4-py3-none-any.whl (1.1 MB)\n",
      "Using cached fiona-1.9.6-cp312-cp312-macosx_10_15_x86_64.whl (18.6 MB)\n",
      "Using cached pyproj-3.6.1-cp312-cp312-macosx_10_9_x86_64.whl (6.1 MB)\n",
      "Using cached shapely-2.0.4-cp312-cp312-macosx_10_9_x86_64.whl (1.4 MB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Using cached cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Installing collected packages: shapely, pyproj, click, cligj, click-plugins, fiona, geopandas\n",
      "Successfully installed click-8.1.7 click-plugins-1.1.1 cligj-0.7.2 fiona-1.9.6 geopandas-0.14.4 pyproj-3.6.1 shapely-2.0.4\n",
      "geopandas has been installed.\n",
      "All packages are up to date.\n"
     ]
    }
   ],
   "source": [
    "from simulation_files.libs.libraries import *\n",
    "from simulation_files.simulation_env import *\n",
    "from simulation_files.mobility.mobility_models import *\n",
    "#from mobility_graphics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulation Parameters:\n",
      "\n",
      "earth_radius_km (km): 6371.0\n",
      "ORIGIN (coordinates (lat, long)): (48.81778, 2.23333)\n",
      "DATA_SOURCE_LINK (URL): https://files.data.gouv.fr/arcep_donnees/mobile/sites/2022_T3/2022_T3_sites_Metropole.csv\n",
      "NET_WIDTH (km): 17.014\n",
      "NET_HEIGHT (km): 9.298\n",
      "SITE_TYPE (type): site_4g\n",
      "OPERATOR (name): Orange\n",
      "GEO_AREA (area): Paris\n",
      "TILE_SIZE (km): 0.025\n",
      "MU_UE (units): 5\n",
      "SIGMA_UE (units): 3\n",
      "POPULATION (people): 11000\n",
      "NETWORK_DENSITY (people/km^2): 69.5339202013055\n",
      "OPERATOR_MARKET_SHARE (fraction): 0.385\n",
      "ACTIVE_UE_FRACTION (fraction): 0.1\n",
      "UE_MAX_TILE_DISTANCE (tiles): 2\n",
      "W (MHz): 20\n",
      "N (dBm/Hz): -100\n",
      "G0 (linear scale): 3\n",
      "BS_P_TX (dBm): 25\n",
      "S (linear scale): 3\n",
      "ALPHA (linear scale): 2\n",
      "BS_MAX_RANGE (km): 10\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSimulation Parameters:\\n\")\n",
    "simulation_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hints:\n",
    "https://github.com/nds-group/netmob2023challenge/blob/main/Traffic.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technical questions\n",
    "- how to perfrom handover (https://devopedia.org/5g-handover)\n",
    "- how to perform paging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "To generate UEs: https://colab.research.google.com/github/pymc-devs/pymc-examples/blob/main/examples/gaussian_processes/log-gaussian-cox-process.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UE:\n",
    "    def __init__(self, ue_id: int, position: Tuple[float, float], tile: int):\n",
    "        \"\"\" \n",
    "        Initialize a User Equipment (UE) object.\n",
    "\n",
    "        Parameters:\n",
    "        - ue_id (int): The ID of the UE.\n",
    "        - position (tuple): The position of the UE.\n",
    "        - tile (int): The tile number of the UE.\n",
    "\n",
    "        Attributes:\n",
    "        - ue_id (int): The ID of the UE.\n",
    "        - position (tuple): The position of the UE.\n",
    "        - tile (int): The tile number of the UE.\n",
    "        - active (bool): Indicates if the UE is active.\n",
    "        - inner_region (bool): Indicates if the UE is in the inner region.\n",
    "        - bs_id (int): The ID of the base station the UE is connected to.\n",
    "        - moving (bool): Indicates if the UE is moving.\n",
    "        - cluster (None or Cluster): The cluster the UE belongs to.\n",
    "        - generator (None or Generator): The moving generator associated with the UE.\n",
    "        \"\"\"\n",
    "        self.ue_id = ue_id\n",
    "        self.position = position\n",
    "        self.tile = tile\n",
    "        self.active = False \n",
    "        self.inner_region = False\n",
    "        self.bs_id = None\n",
    "        self.moving = False\n",
    "        self.cluster = None\n",
    "        self.generator = None\n",
    "    \n",
    "    def get_id(self):\n",
    "        return self.ue_id\n",
    "\n",
    "    def set_active(self):\n",
    "        \"\"\" \n",
    "        Set the UE as active.\n",
    "        \"\"\"\n",
    "        self.active = True\n",
    "\n",
    "    def set_inactive(self):\n",
    "        \"\"\" \n",
    "        Set the UE as inactive and clear its attributes.\n",
    "        \"\"\"\n",
    "        self.active = False\n",
    "        # Clear the base station\n",
    "        # Sanity check\n",
    "        if self.bs_id is not None: self.bs_id = None\n",
    "        # Clear variables\n",
    "        self.inner_region = False\n",
    "        self.moving = False\n",
    "        self.generator = None\n",
    "        self.position = None\n",
    "        self.tile = None\n",
    "        self.cluster = None\n",
    "\n",
    "    def get_info(self):\n",
    "        \"\"\"\n",
    "        Get information about the UE.\n",
    "\n",
    "        Returns:\n",
    "        - dict: A dictionary containing the UE's information.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'UE ID': self.ue_id,\n",
    "            'Position': self.position,\n",
    "            'Tile': self.tile,\n",
    "            'Active': self.active,\n",
    "            'Inner Region': self.inner_region, \n",
    "            'BS ID': self.bs_id,\n",
    "            'Moving': self.moving,\n",
    "            'Generator': self.generator,\n",
    "            'Cluster': self.cluster  \n",
    "        }\n",
    "\n",
    "    def get_geo_coordinate(self):\n",
    "        \"\"\"\n",
    "        Get the geographical coordinates of the UE based on the reference position of origin.\n",
    "\n",
    "        Returns:\n",
    "        - tuple: The latitude and longitude of the UE's position.\n",
    "        \"\"\"\n",
    "        # NB\n",
    "        # source: http://www.edwilliams.org/avform147.htm\n",
    "        # and https://gis.stackexchange.com/questions/2951/algorithm-for-offsetting-a-latitude-longitude-by-some-amount-of-meters/2980#2980?newreg=0bedc72752ea4e629440a761d6f4a231\n",
    "        # ORIGIN = (Latitude, Longitude) \n",
    "        # self.position = (x, y) in km x=>longitude, y=>latitude\n",
    "\n",
    "        # Convert latitude and longitude to radians\n",
    "        lat_rad = math.radians(ORIGIN[0])\n",
    "        # lon_rad = math.radians(ORIGIN[1])\n",
    "\n",
    "        # Calculate the change in latitude\n",
    "        delta_lat = self.position[1] / earth_radius_km\n",
    "\n",
    "        # Calculate the change in longitude\n",
    "        delta_lon = self.position[0] / (earth_radius_km * math.cos(lat_rad))\n",
    "\n",
    "        # Convert the changes to degrees\n",
    "        delta_lat_deg = math.degrees(delta_lat)\n",
    "        delta_lon_deg = math.degrees(delta_lon)\n",
    "\n",
    "        # Calculate the new latitude and longitude\n",
    "        new_latitude = ORIGIN[0] + delta_lat_deg\n",
    "        new_longitude = ORIGIN[1] + delta_lon_deg\n",
    "\n",
    "        return new_latitude, new_longitude\n",
    "    \n",
    "    def move(self):\n",
    "        \"\"\"\n",
    "        Move the UE based on the generator associated with the UE's cluster.\n",
    "        \"\"\"\n",
    "        # if not self.generator:\n",
    "        #     self.generator = gauss_markov_trajectory(position=self.cluster.destination, dimensions=(NET_WIDTH, NET_HEIGHT), group_velocity_mean=self.cluster.group_velocity_mean, \n",
    "        #                                      group_theta_mean=self.cluster.group_theta_mean, group_alpha=self.cluster.group_alpha, group_variance=self.cluster.group_variance)\n",
    "              \n",
    "        # self.position, _, _ = next(self.generator)\n",
    "        pass\n",
    "        #or em_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cluster():\n",
    "    def __init__(self, id: int, group_velocity_mean: float =1., group_theta_mean: float =np.pi/2, group_alpha: float =1., group_variance: float =1):\n",
    "        \"\"\"\n",
    "        Initialize a Cluster object.\n",
    "\n",
    "        Parameters:\n",
    "        - id (int): The ID of the cluster.\n",
    "        - group_velocity_mean (float): The mean velocity of the group.\n",
    "        - group_theta_mean (float): The mean angle of movement of the group.\n",
    "        - group_alpha (float): The alpha parameter of the group.\n",
    "        - group_variance (float): The variance parameter of the group.\n",
    "\n",
    "        Attributes:\n",
    "        - id (int): The ID of the cluster.\n",
    "        - group_velocity_mean (float): The mean velocity of the group.\n",
    "        - group_theta_mean (float): The mean angle of movement of the group.\n",
    "        - group_alpha (float): The alpha parameter of the group.\n",
    "        - group_variance (float): The variance parameter of the group.\n",
    "        - paired_ues (list): The list of paired UEs.\n",
    "        - destination (tuple): The current destination of the group.\n",
    "        - generator (None or Generator): The moving generator associated with the group.\n",
    "        - history (list): The history of destinations visited by the group.\n",
    "        \"\"\"\n",
    "        self.id = id\n",
    "        self.group_velocity_mean = group_velocity_mean\n",
    "        self.group_theta_mean = group_theta_mean\n",
    "        self.group_alpha = group_alpha\n",
    "        self.group_variance = group_variance\n",
    "        self.paired_ues = []\n",
    "        self.destination = (None, None)\n",
    "        self.generator = None\n",
    "        self.history = [] #to record trajectory\n",
    "    \n",
    "    def get_id(self):\n",
    "        return self.id\n",
    "\n",
    "    def resample_params(self):\n",
    "        \"\"\" \n",
    "        Resamples the movement parameters of the cluster using uniform distributions. This method adjusts the cluster's velocity, direction, alpha, and variance attributes.\n",
    "        \"\"\"\n",
    "        max_velox = 50 * (1/3600) #km/s. we can set it to 50km/h for urban centers\n",
    "        min_velox = 5 * (1/3600) #km/s. (assumin 5 km/h which is the average speed of a walk) Going at 5 km/h would take 18 seconds to cover one TILE_SIZE\n",
    "        self.group_velocity_mean = U(min_velox, max_velox) #defined in km/h\n",
    "        self.group_theta_mean = U(0, 2*np.pi)\n",
    "        self.group_alpha = U(0.1, 1)\n",
    "        self.group_variance = U(0.5, 5)\n",
    "\n",
    "    def add_ue(self, ue: UE):\n",
    "        \"\"\"\n",
    "        Adds a UE to the cluster's list of paired UEs.\n",
    "        \n",
    "        Parameters:\n",
    "        - ue (UE): The UE object to be added to the cluster.\n",
    "        \"\"\"\n",
    "        self.paired_ues.append(ue)\n",
    "    \n",
    "    def remove_ue(self, ue_id: int):\n",
    "        \"\"\"\n",
    "        Removes a UE from the cluster based on its ID.\n",
    "        \n",
    "        Parameters:\n",
    "        - ue_id (int): The ID of the UE to be removed.\n",
    "        \"\"\"\n",
    "        #remove ue with matching UE_id\n",
    "        for ue in self.paired_ues:\n",
    "            if ue.ue_id == ue_id:\n",
    "                self.paired_ues.remove(ue)\n",
    "\n",
    "    def set_first_destination(self, position: np.ndarray):\n",
    "        \"\"\"\n",
    "        Sets the initial destination for the cluster and initializes the movement generator.\n",
    "        \n",
    "        Parameters:\n",
    "        - destination (tuple): The initial destination coordinates for the cluster.\n",
    "        \"\"\"\n",
    "\n",
    "        self.generator = gauss_markov_trajectory(position = position, dimensions = (NET_WIDTH,NET_HEIGHT), group_velocity_mean=self.group_velocity_mean, \n",
    "                                             group_theta_mean=self.group_theta_mean, group_alpha=self.group_alpha, group_variance=self.group_variance)\n",
    "        #or em_trajectory\n",
    "        self.move_destination()\n",
    "\n",
    "    def move_destination(self):\n",
    "        \"\"\"\n",
    "        Updates the cluster's destination using the movement generator and records the new destination.\n",
    "        \"\"\"\n",
    "        self.destination, _ , _ = next(self.generator)\n",
    "        self.history.append(self.destination)  # Record each new destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BS():\n",
    "    def __init__(self, controller: Controller, bs_id: int, position = Tuple[float, float]):\n",
    "\n",
    "        \"\"\"\n",
    "        Initializes a new instance of the BS (Base Station) class which represents a base station in a cellular network.\n",
    "\n",
    "        Parameters:\n",
    "        - bs_id (int): The identifier for the base station.\n",
    "        - position (tuple): The geographic coordinates of the base station.\n",
    "        \n",
    "        Attributes:\n",
    "        - bw (float): Bandwidth available to the base station.\n",
    "        - g0 (float): Reference path loss at a distance of 1 meter.\n",
    "        - p_tx (float): Transmit power of the base station.\n",
    "        - noise_density (float): Noise density in the network.\n",
    "        - shadowing (float): Shadowing effect on the signal, specific to each UE.\n",
    "        - alpha (float): Path loss exponent.\n",
    "        \"\"\"\n",
    "\n",
    "        self.bs_id = bs_id\n",
    "        self.position = position\n",
    "        self.cntr = controller\n",
    "        self.bw= W \n",
    "        self.g0 = G0\n",
    "        self.p_tx = BS_P_TX \n",
    "        self.noise_density = N\n",
    "        self.shadowing = S\n",
    "        self.alpha = ALPHA\n",
    "        self.p_tx_in, self.p_tx_out = None, None\n",
    "        self.served_UEs = [] #memorize the UE object\n",
    "        self.update_snr_thr = True\n",
    "        self.snr_thr = None\n",
    "        self.bs_sector = None\n",
    "        self.power_adjustment()\n",
    "\n",
    "    def get_id(self):\n",
    "        return self.bs_id\n",
    "    \n",
    "    def ue_sorting(self):\n",
    "        \"\"\"\n",
    "        Sorts the UEs based on their SNR values, descending order.\n",
    "        \"\"\"\n",
    "        self.served_UEs = sorted(self.served_UEs, key=lambda ue: self.compute_snr(ue), reverse=True)\n",
    "\n",
    "    def power_adjustment(self, power_levels: Optional[float]= None):\n",
    "        \"\"\"\n",
    "        Adjusts the power output levels for the base station.\n",
    "        \"\"\"\n",
    "        #variables: self.p_tx_in, self.p_tx_out\n",
    "        #max_cap: BS_P_TX\n",
    "        #contraints: self.p_tx_out > self.p_tx_in as long as h_out < h_in\n",
    "        #obj function to max\n",
    "        if power_levels is None:\n",
    "            self.p_tx_out = 0.6* BS_P_TX\n",
    "            self.p_tx_in = BS_P_TX - self.p_tx_out\n",
    "        else:\n",
    "            #@TODO be sure to use the right level, you might to apply the median on tuples \n",
    "            self.p_tx_in,self.p_tx_out  = median(power_levels, axis = 1) \n",
    "\n",
    "    \n",
    "    #need to implement the alpha-fairness formulation\n",
    "    def retreive_snr_thr(self, low_complex: bool = False): #as I have not implmented the BO obj function yet, I use a median to compute the snr threshold\n",
    "        \"\"\"\n",
    "        Computes the SNR threshold by taking the median of the SNRs of all served UEs. This is used to determine which UEs are in the inner region of coverage.\n",
    "        \"\"\"\n",
    "        #tune this\n",
    "        low_complex = False\n",
    "        ###\n",
    "        assert self.served_UEs, 'Empty user set'\n",
    "        self.ue_sorting()\n",
    "        if low_complex:\n",
    "            snr_lst = [self.compute_snr(ue) for ue in self.served_UEs]\n",
    "            self.snr_thr = median(snr_lst)\n",
    "        else:\n",
    "            #given the ues sorted in discending order, get the partition that yelds the highest value of the objective function. The objective function computes w.r.t the UE's SINR for all the uses served.\n",
    "            #the partition is the one that maximizes the objective function\n",
    "            ue_max = None\n",
    "            prior = 0\n",
    "            ue_trace = []\n",
    "            bs = self.cntr.bs_lookup(self.bs_id)\n",
    "            for ue in self.served_UEs:\n",
    "                ue_trace.append(ue)\n",
    "                post = self.cntr.objective_function(bss = [bs], ues_test = ue_trace)[0]\n",
    "                if post > prior:\n",
    "                    ue_max = ue\n",
    "                    prior = post\n",
    "            \n",
    "            self.snr_thr = self.compute_snr(ue_max)\n",
    "                \n",
    "\n",
    "    \n",
    "    def add_ue(self, ue: UE): \n",
    "        \"\"\"\n",
    "        Adds a UE to the list of UEs served by this base station. Also triggers intra-cell assignment to determine if the UE is within the inner region based on SNR.\n",
    "        \n",
    "        Parameters:\n",
    "        - ue (UE): The user equipment instance to be added.\n",
    "        \"\"\"\n",
    "        self.served_UEs.append(ue)\n",
    "        self.intra_cell_assignment(ue) \n",
    "        self.update_snr_thr = True\n",
    "\n",
    "    def intra_cell_assignment(self, ue: UE):\n",
    "        \"\"\"\n",
    "        Determines whether the given UE is within the inner region of coverage based on its SNR compared to the SNR threshold.\n",
    "        \n",
    "        Parameters:\n",
    "        - ue (UE): The user equipment instance being evaluated.\n",
    "        \"\"\"\n",
    "        if (self.snr_thr is None) or self.update_snr_thr:\n",
    "            self.retreive_snr_thr()\n",
    "            self.update_snr_thr = False\n",
    "        #agin consider that the real SNR measurement is backpropagated from the UE to the BS, \n",
    "        #here we compute at the BS side as it was the DL SNR\n",
    "        snr_ue = self.compute_snr(ue)\n",
    "        ue.inner_region = snr_ue > self.snr_thr \n",
    "        # if snr_ue > self.snr_thr:\n",
    "        #     inner_flag = True\n",
    "        # else:\n",
    "        #     inner_flag = False\n",
    "        # ue.inner_region = inner_flag\n",
    "\n",
    "    def remove_ue(self, ue: UE):\n",
    "        \"\"\"\n",
    "        Removes a UE from the base station's list of served UEs and recalculates the SNR threshold.\n",
    "        \n",
    "        Parameters:\n",
    "        - ue (UE): The user equipment instance to be removed.\n",
    "        \"\"\"\n",
    "        self.served_UEs.remove(ue)\n",
    "        if self.served_UEs: \n",
    "            self.retreive_snr_thr() #update the snr_thr\n",
    "    \n",
    "    def get_distance(self, ue:UE):\n",
    "        \"\"\"\n",
    "        Calculates the eucledian distance between the base station and a UE.\n",
    "        \n",
    "        Parameters:\n",
    "        - ue (UE): The user equipment whose distance is to be calculated.\n",
    "        \"\"\"\n",
    "        return math.sqrt(sum((x1 - x2) ** 2 for x1, x2 in zip(self.position, ue.position)))\n",
    "\n",
    "    def compute_link_gain(self, ue:UE):\n",
    "        \"\"\"\n",
    "        Computes the link gain between the base station and a UE using a standard path loss model.\n",
    "        \n",
    "        Parameters:\n",
    "        - ue (UE): The user equipment for which link gain is computed.\n",
    "        \"\"\"\n",
    "        d = self.get_distance(ue)\n",
    "        return self.g0 * self.shadowing * (d**(-self.alpha)) #standard path loss model in nominal, LOS conditions\n",
    "\n",
    "    def compute_snr(self, ue: UE):\n",
    "        \"\"\"\n",
    "        Calculates the Signal-to-Noise Ratio (SNR) for a UE based on its position, either the inner or outer region.\n",
    "        \n",
    "        Parameters:\n",
    "        - ue (UE): The user equipment for which SNR is computed.\n",
    "        \"\"\"\n",
    "\n",
    "        # if ue.inner_region:\n",
    "        #     pw = self.p_tx_in\n",
    "        # else:\n",
    "        #     pw = self.p_tx_out\n",
    "        # snr = (pw*self.compute_link_gain(ue=ue))/(self.noise_density*self.bw)\n",
    "        # return snr\n",
    "        pw = self.p_tx_in if ue.inner_region else self.p_tx_out\n",
    "        return (pw * self.compute_link_gain(ue)) / (self.noise_density * self.bw)\n",
    "  \n",
    "    #eventual functions that allow to modify simulation parameters during the simulation\n",
    "    def modify_params(self, bw: float = None, g0: float = None,shadowing: float = None,alpha: float =None, p_tx: float = None, noise: float = None):\n",
    "        \"\"\"\n",
    "        Modifies various parameters of the base station dynamically, based on the inputs provided. Each parameter is optional.\n",
    "        \n",
    "        Parameters:\n",
    "        - bw (float): New bandwidth.\n",
    "        - g0 (float): New reference path loss value.\n",
    "        - p_tx (float): New transmit power.\n",
    "        - noise (float): New noise density.\n",
    "        - shadowing (float): New shadowing effect.\n",
    "        - alpha (float): New path loss exponent.\n",
    "        \"\"\"\n",
    "        if bw is not None:\n",
    "            self.bw = bw\n",
    "        if g0 is not None:\n",
    "            self.g0 = g0\n",
    "        if p_tx is not None:\n",
    "            self.p_tx = p_tx\n",
    "        if noise is not None:\n",
    "            self.noise_density = noise\n",
    "        if shadowing is not None:\n",
    "            self.shadowing = shadowing\n",
    "        if alpha is not None:\n",
    "            self.alpha = alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controller:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes a new instance of the Controller class, which manages user equipment (UEs) and base stations (BSs) in a cellular network system.\n",
    "        \"\"\"\n",
    "        self.UEs = []  # List[UE]\n",
    "        self.BSs = []  # List[BS]\n",
    "        self.alpha_fairness = None\n",
    "        \n",
    "    def _lookup(self, items: List, identifier: int) -> Optional:\n",
    "        \"\"\"\n",
    "        General-purpose method to retrieve an object from a list using its identifier.\n",
    "        \n",
    "        Parameters:\n",
    "        - items (List): List of items to search through.\n",
    "        - identifier (int): The identifier of the item to retrieve.\n",
    "        \n",
    "        Returns:\n",
    "        - Optional: The item object if found, None otherwise.\n",
    "        \"\"\"\n",
    "        if items:\n",
    "            return next((item for item in items if item.get_id() == identifier), None)\n",
    "        return None\n",
    "\n",
    "    def bs_lookup(self, bs_id: int = None) -> Optional[BS]:\n",
    "        \"\"\"\n",
    "        Retrieves a base station object from the list of base stations using its identifier.\n",
    "        \n",
    "        Parameters:\n",
    "        - bs_id (int): The identifier of the base station to retrieve.\n",
    "        \n",
    "        Returns:\n",
    "        - Optional[BS]: The base station object if found, None otherwise.\n",
    "        \"\"\"\n",
    "        return self._lookup(self.BSs, bs_id) if bs_id is not None else None\n",
    "    \n",
    "    def ue_lookup(self, ue_id: int = None) -> Optional[UE]:\n",
    "        \"\"\"\n",
    "        Retrieves a user equipment object from the list of UEs using its identifier.\n",
    "        \n",
    "        Parameters:\n",
    "        - ue_id (int): The identifier of the user equipment to retrieve.\n",
    "        \n",
    "        Returns:\n",
    "        - Optional[UE]: The user equipment object if found, None otherwise.\n",
    "        \"\"\"\n",
    "        return self._lookup(self.UEs, ue_id) if ue_id is not None else None\n",
    "\n",
    "\n",
    "    def bs_paging(self):\n",
    "        \"\"\"\n",
    "        Implement paging to locate a UE within the network.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    # def bs_handover(self, ue: UE):\n",
    "    #     \"\"\"\n",
    "    #     Manages the handover of a UE from one base station to another based on signal-to-noise ratio (SINR) metrics.\n",
    "    #     - Computes the SINR for all eligible BSs.\n",
    "    #     - Assigns the UE to the BS with the highest SINR.\n",
    "    #     - Triggers the intracell assignment process to adjust the UE's service quality or region.\n",
    "\n",
    "    #     Parameters:\n",
    "    #     - ue (UE): The user equipment undergoing handover.\n",
    "    #     \"\"\"\n",
    "        \n",
    "    #     # eligible_bs = copy.deepcopy(self.BSs) #copy of the list of BSs\n",
    "    #     # current_bs = self.bs_lookup(bs_id = ue.bs_id)\n",
    "    #     # # current_bs = None\n",
    "\n",
    "    #     # # if ue.bs_id is not None:\n",
    "    #     # #     current_bs = self.bs_lookup(bs_id = ue.bs_id)\n",
    "    #     # #     eligible_bs.remove(current_bs)\n",
    "\n",
    "    #     # if (current_bs is None) or (current_bs.get_distance(ue) >= BS_MAX_RANGE): #change BS\n",
    "            \n",
    "    #     #     if current_bs is not None:\n",
    "    #     #         eligible_bs.remove(current_bs)\n",
    "    #     #         current_bs.remove_ue(ue)\n",
    "            \n",
    "    #     #     max_sinr_ix = argmax(np.array([self.compute_sinr(bs, ue) for bs in eligible_bs])) #that would be the UL SINR, for pairing\n",
    "\n",
    "    #     #     selected_bs = eligible_bs[max_sinr_ix]\n",
    "\n",
    "    #     #     selected_bs.add_ue(ue) #==> trigger intracell assignment\n",
    "    #     #     ue.bs_id = selected_bs.bs_id\n",
    "\n",
    "    #     # if ue.moving:\n",
    "    #     #     ue.moving = False\n",
    "    #     ue_in_range = True\n",
    "\n",
    "    #     current_bs = self.bs_lookup(ue.bs_id)\n",
    "\n",
    "    #     eligible_bs = [bs for bs in self.BSs if bs.get_distance(ue) < BS_MAX_RANGE] \n",
    "\n",
    "    #     if current_bs is None or current_bs.get_distance(ue) >= BS_MAX_RANGE:\n",
    "\n",
    "    #         if current_bs is not None:\n",
    "    #             current_bs.remove_ue(ue)\n",
    "            \n",
    "    #         if not eligible_bs:\n",
    "    #             print(\"User not reachable from BSs\")\n",
    "    #             print(f'Kill user {ue.ue_id}')\n",
    "    #             ue_in_range = False# Early exit if no BS is eligible\n",
    "\n",
    "    #         current_bs = max(eligible_bs, key=lambda bs: self.compute_sinr(bs, ue, eligible_bs))\n",
    "\n",
    "    #         current_bs.add_ue(ue) #here will trigger the intra-cell region assignment\n",
    "            \n",
    "    #         ue.bs_id = current_bs.bs_id\n",
    "\n",
    "    #     ue.moving = False\n",
    "\n",
    "    #     self.compute_sinr(bs = current_bs, ue=ue, eligible_bs = eligible_bs) #update the sinr metrics\n",
    "\n",
    "    #     return ue_in_range\n",
    "\n",
    "    # def compute_sinr(self, bs: BS, ue: UE, eligible_bs: List[BS])->float:\n",
    "    #     \"\"\"\n",
    "    #     Computes the downlink SINR for a given UE at a specified base station.\n",
    "        \n",
    "    #     Parameters:\n",
    "    #     - bs (BS): The base station.\n",
    "    #     - ue (UE): The user equipment.\n",
    "        \n",
    "    #     Returns:\n",
    "    #     - float: The computed SINR.\n",
    "    #     \"\"\"\n",
    "\n",
    "    #     dl_sinr = None \n",
    "\n",
    "    #     ue_just_spawned = ue.dl_sinr is None\n",
    "\n",
    "    #     pairing_flag = ue.moving or ue_just_spawned\n",
    "\n",
    "    #     bs_interference_set = [b for b in eligible_bs if b != bs]\n",
    "\n",
    "    #     noise = bs.bw * bs.noise_density\n",
    "\n",
    "    #     inter_cell_interf = sum([b.compute_link_gain(ue)*(b.p_tx_in + b.p_tx_out) for b in bs_interference_set]) #in the case some BS do not have the same power or gain\n",
    "\n",
    "    #     interference = noise + inter_cell_interf\n",
    "\n",
    "    #     link_gain = bs.compute_link_gain(ue)\n",
    "\n",
    "    #     if pairing_flag or not ue.inner_region:\n",
    "\n",
    "    #         intra_cell_interf = link_gain*bs.p_tx_in\n",
    "\n",
    "    #         interference += intra_cell_interf \n",
    "\n",
    "    #         dl_sinr = (link_gain*bs.p_tx_out)/interference\n",
    "    #     else:\n",
    "    #         dl_sinr = (link_gain*bs.p_tx_in)/interference\n",
    "        \n",
    "    #     if not pairing_flag:\n",
    "    #         ue.dl_sinr = dl_sinr\n",
    "    #         print('UE_ID: ', ue.ue_id, ' SINR: ', ue.dl_sinr)\n",
    "    #     # print(link_gain*bs.p_tx_in)\n",
    "    #     # print(interference)\n",
    "\n",
    "    #     return dl_sinr\n",
    "    def bs_handover(self, ue: UE):\n",
    "        \"\"\"\n",
    "        Manages the handover of a UE from one base station to another based on signal-to-noise ratio (SINR) metrics.\n",
    "        - Computes the SINR for all eligible BSs.\n",
    "        - Assigns the UE to the BS with the highest SINR.\n",
    "        - Triggers the intracell assignment process to adjust the UE's service quality or region.\n",
    "\n",
    "        Parameters:\n",
    "        - ue (UE): The user equipment undergoing handover.\n",
    "        \"\"\"\n",
    "        \n",
    "        # eligible_bs = copy.deepcopy(self.BSs) #copy of the list of BSs\n",
    "        # current_bs = self.bs_lookup(bs_id = ue.bs_id)\n",
    "        # # current_bs = None\n",
    "\n",
    "        # # if ue.bs_id is not None:\n",
    "        # #     current_bs = self.bs_lookup(bs_id = ue.bs_id)\n",
    "        # #     eligible_bs.remove(current_bs)\n",
    "\n",
    "        # if (current_bs is None) or (current_bs.get_distance(ue) >= BS_MAX_RANGE): #change BS\n",
    "            \n",
    "        #     if current_bs is not None:\n",
    "        #         eligible_bs.remove(current_bs)\n",
    "        #         current_bs.remove_ue(ue)\n",
    "            \n",
    "        #     max_sinr_ix = argmax(np.array([self.compute_sinr(bs, ue) for bs in eligible_bs])) #that would be the UL SINR, for pairing\n",
    "\n",
    "        #     selected_bs = eligible_bs[max_sinr_ix]\n",
    "\n",
    "        #     selected_bs.add_ue(ue) #==> trigger intracell assignment\n",
    "        #     ue.bs_id = selected_bs.bs_id\n",
    "\n",
    "        # if ue.moving:\n",
    "        #     ue.moving = False\n",
    "        def subroutine(ue:UE, eligible_bs: List[BS]):\n",
    "            bs = max(eligible_bs, key=lambda bs: self.compute_sinr(bs = bs, ue = ue, interference_set=eligible_bs, pairing= True))\n",
    "            bs.add_ue(ue) #here will trigger the intra-cell region assignment\n",
    "            ue.bs_id = bs.get_id()\n",
    "            #ue.dl_sinr = self.compute_sinr(bs, ue, interference_set)\n",
    "\n",
    "        ue_in_range = True\n",
    "\n",
    "        current_bs = self.bs_lookup(ue.bs_id)\n",
    "\n",
    "        ue_just_spawned = current_bs is None\n",
    "\n",
    "        eligible_bs = [b for b in self.BSs if b.get_distance(ue) < BS_MAX_RANGE]\n",
    "\n",
    "        if not eligible_bs:\n",
    "                print(\"User not reachable from BSs\")\n",
    "                print(f'Kill user {ue.ue_id}')\n",
    "                ue_in_range = False# Early exit if no BS is eligible\n",
    "\n",
    "        elif ue_just_spawned:\n",
    "            subroutine(ue,eligible_bs)\n",
    "        \n",
    "        elif ue.moving and current_bs.get_distance(ue) >= BS_MAX_RANGE: \n",
    "                \n",
    "                current_bs.remove_ue(ue)\n",
    "                ue.moving = False\n",
    "                subroutine(ue, eligible_bs)\n",
    "        #else:\n",
    "            #subroutine(current_bs, ue, eligible_bs)\n",
    "        #print('UE_ID: ', ue.ue_id, ' SINR: ', ue.dl_sinr)\n",
    "\n",
    "        return ue_in_range\n",
    "        \n",
    "\n",
    "    def compute_sinr(self, bs: BS, ue: UE, pairing:bool, interference_set: List[BS] = None, inner_test: bool = False)->float:\n",
    "        \"\"\"\n",
    "        Computes the downlink SINR for a given UE at a specified base station.\n",
    "        \n",
    "        Parameters:\n",
    "        - bs (BS): The base station.\n",
    "        - ue (UE): The user equipment.\n",
    "        \n",
    "        Returns:\n",
    "        - float: The computed SINR.\n",
    "        \"\"\"\n",
    "\n",
    "        dl_sinr = .0 \n",
    "\n",
    "        if interference_set is None:\n",
    "            bs_interference_set = [b for b in self.BSs if b.get_distance(ue) < BS_MAX_RANGE]\n",
    "        else:\n",
    "            bs_interference_set = [b for b in interference_set if b!=bs]\n",
    "\n",
    "        noise = bs.bw * bs.noise_density\n",
    "\n",
    "        inter_cell_interf = sum([b.compute_link_gain(ue)*(b.p_tx_in + b.p_tx_out) for b in bs_interference_set]) #in the case some BS do not have the same power or gain\n",
    "\n",
    "        interference = noise + inter_cell_interf\n",
    "\n",
    "        link_gain = bs.compute_link_gain(ue)\n",
    "\n",
    "        if pairing:\n",
    "\n",
    "            intra_cell_interf = link_gain*bs.p_tx_in\n",
    "\n",
    "            interference += intra_cell_interf \n",
    "\n",
    "            dl_sinr = (link_gain*bs.p_tx_out)/interference\n",
    "\n",
    "        elif ue.inner_region or inner_test:\n",
    "              \n",
    "              dl_sinr = (link_gain*bs.p_tx_in)/interference\n",
    "\n",
    "        else:\n",
    "            intra_cell_interf = link_gain*bs.p_tx_in\n",
    "\n",
    "            interference += intra_cell_interf \n",
    "\n",
    "            dl_sinr = (link_gain*bs.p_tx_out)/interference\n",
    "\n",
    "        return dl_sinr\n",
    "    \n",
    "    def kill_ue(self, ue: UE):\n",
    "        \"\"\"\n",
    "        Removes a UE from the system entirely, including dissociation from the BS and marking the UE as inactive.\n",
    "        \n",
    "        Parameters:\n",
    "        - ue (UE): The user equipment to be removed.\n",
    "        \"\"\"\n",
    "        current_bs = self.bs_lookup(bs_id = ue.bs_id)\n",
    "        current_bs.remove_ue(ue)\n",
    "        ue.set_inactive() #==> here it will dissociate from the bs\n",
    "        self.UEs.remove(ue)\n",
    "\n",
    "    def add_ue(self, ue:UE):\n",
    "        \"\"\"\n",
    "        Adds a new UE to the system, sets it as active, and performs an initial base station assignment.\n",
    "        \n",
    "        Parameters:\n",
    "        - ue (UE): The user equipment to be added.\n",
    "        \"\"\"\n",
    "        self.UEs.append(ue)\n",
    "        ue.set_active()\n",
    "        return self.bs_handover(ue)\n",
    "\n",
    "    def gather_metrics(self):\n",
    "        \"\"\"\n",
    "        Collects and returns the SINR metrics for each UE served by its BS in the network.\n",
    "        \n",
    "        Returns:\n",
    "        - dict: {'median_sinr': float, 'average_sinr': float} the median and average SINR across the network.\n",
    "        \"\"\"\n",
    "        metrics_ = [self.compute_sinr(bs=self.bs_lookup(ue.bs_id), ue=ue, pairing=False) for ue in self.UEs]\n",
    "        # for ue in self.UEs:\n",
    "        #     bs_metrics = [ue.dl_sinr for ue in bs.served_UEs]\n",
    "        #     #print(bs)\n",
    "        #     #print(bs.served_UEs)\n",
    "        #     #print(bs_metrics)\n",
    "        #     metrics_.extend(bs_metrics)\n",
    "        rounder = lambda x: round(x,5)\n",
    "        return {'median_sinr': rounder(median(metrics_)), 'average_sinr': rounder(mean(metrics_))}\n",
    "\n",
    "\n",
    "    def objective_function(self, bss: List[BS], ues_test: List[UE] = [], alpha_fairness: float = 1.0):\n",
    "        \"\"\"\n",
    "        Defines the objective function for the base station.\n",
    "        \"\"\"\n",
    "        alpha_fairness = self.alpha_fairness\n",
    "\n",
    "        normalizer = lambda bs, lst: np.array(lst)/np.sum(lst) if alpha_fairness != 0 else [1 if ue == bs.served_UEs[argmax(np.array(lst))] else 0 for ue in bs.served_UEs]\n",
    "\n",
    "        objective_func = lambda lst: np.sum(np.log(np.array(lst))) if alpha_fairness == 1 else np.sum((np.array(lst)**(1-alpha_fairness))/(1-alpha_fairness))\n",
    "\n",
    "        shannon_capacity = lambda bs, ue, ue_inner_test : bs.bw * math.log(1 + self.compute_sinr(bs=bs, ue=ue, pairing=False, inner_test=ue_inner_test),2)\n",
    "\n",
    "        scheduler = lambda bs, ue, ue_inner_test:  (shannon_capacity(bs, ue, ue_inner_test)**(1-alpha_fairness))/ alpha_fairness if alpha_fairness != 0 else shannon_capacity(bs, ue, ue_inner_test)\n",
    "        \n",
    "        lister = lambda bs: [scheduler(bs, ue, ue in ues_test) for ue in bs.served_UEs]\n",
    "\n",
    "        return [objective_func(normalizer(bs, lister(bs))) for bs in bss]\n",
    "\n",
    "    \n",
    "        # return objective_func(scheduling, alpha_fairness)\n",
    "    def set_sectors(self):\n",
    "         #supposing all the BSs have the same MAX range\n",
    "        for bs in self.BSs:\n",
    "            #get the interference set of the base station\n",
    "            bs.sector = [b for b in self.BSs if b != bs and bs.get_distance(b) < 2*BS_MAX_RANGE]\n",
    "    \n",
    "    def optimize_power(self):\n",
    "        \"\"\"\n",
    "        Implements a consensus algorithm to adjust the power levels of the base stations withing a common sector.\n",
    "        \"\"\"\n",
    "        for bs in self.BSs:\n",
    "            #get the recoomendation from the sector\n",
    "            #trigger optimization\n",
    "            bs.power_adjstument(self.objective_function(bss = bs.sector))\n",
    "\n",
    "    def build_ues_db(self, filename: str):\n",
    "        \"\"\"\n",
    "        Builds and exports a database of UEs with their current information to a CSV file.\n",
    "        \n",
    "        Parameters:\n",
    "        - filename (str): The path to the CSV file where data will be stored.\n",
    "        \"\"\"\n",
    "        data = [ue.get_info() for ue in self.UEs]\n",
    "        ues_db = pd.DataFrame(data)\n",
    "        ues_db.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryHandler(logging.Handler):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.records = []\n",
    "\n",
    "    def emit(self, record):\n",
    "        self.records.append(self.format(record))\n",
    "\n",
    "class JsonFormatter(logging.Formatter):\n",
    "    def format(self, record):\n",
    "        message = record.msg\n",
    "        if isinstance(message, dict):\n",
    "            return json.dumps(message)\n",
    "        return json.dumps({\"message\": message})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#following the process used in \"Assessing the Performance of NOMA in a Multi-Cell Context: A General Evaluation Framework\"\n",
    "class SIMULATION():\n",
    "    \"\"\"\n",
    "    A simulation framework for evaluating the performance of NOMA in a cell-free context, \n",
    "    based on dynamic user equipment (UE) behavior and base station (BS) interaction.\n",
    "    \"\"\" \n",
    "\n",
    "    def __init__(self, controller: Controller, id:int=1, prob_map: List = None,tau: float = 1, lambda_: float = 2, mu: float = 4, epsilon: float = 0.4, move_interval: int = 3): #rho = lambda/mu < 1\n",
    "        \"\"\"\n",
    "        Initializes the simulation environment, sets parameters for the simulation, and optionally, an initial probability map for UE distribution across tiles.\n",
    "\n",
    "        Parameters:\n",
    "        - controller (Controller): The control unit handling all UEs and BSs in the simulation.\n",
    "        - prob_map (list, optional): A list indicating the initial probability of UE distribution across tiles.\n",
    "        - tau (float): Interval for collecting SINR metrics.\n",
    "        - lambda_ (float): Rate of UE arrivals.\n",
    "        - mu (float): Rate of UE departures.\n",
    "        - epsilon (float): Probability of exploration in UE movement.\n",
    "        - move_interval (int): Interval in seconds between each movement update for UEs.\n",
    "\n",
    "        Attributes:\n",
    "        - n_tiles (int): Number of tiles across the simulated area.\n",
    "        - num_tiles_x (int): Number of tiles along the width of the simulated area.\n",
    "        - num_tiles_y (int): Number of tiles along the height of the simulated area.\n",
    "        - env (simpy.Environment): The simulation environment from SimPy.\n",
    "        - history_logger (logging.Logger): Logger for recording simulation history and metrics.\n",
    "        \"\"\"\n",
    "        self.id = id\n",
    "        self.controller = controller\n",
    "        #self.n_tiles = int((NET_WIDTH*NET_HEIGHT)// (TILE_SIZE**2))\n",
    "        self.num_tiles_x = int(NET_WIDTH // TILE_SIZE)\n",
    "        self.num_tiles_y = int(NET_HEIGHT // TILE_SIZE)\n",
    "        self.n_tiles = self.num_tiles_x * self.num_tiles_y\n",
    "        self.env = simpy.Environment()\n",
    "        self.tau = tau  # Interval for SINR metrics collection in seconds\n",
    "        self.lambda_ = lambda_  # User birth rate\n",
    "        self.mu = mu  # User lifetime rate parameter\n",
    "        self.move_interval = move_interval  # Time interval for user movement\n",
    "        self.epsilon = epsilon  # Probability of exploration in movement\n",
    "        if prob_map is not None:\n",
    "            self.prob_map = prob_map\n",
    "        else:\n",
    "            self.prob_map_random_initialization()\n",
    "        self.clusters = None\n",
    "\n",
    "        #run the simulation\n",
    "        # Set up a logging system to collect time and SINR metrics\n",
    "        #logging.basicConfig(level=logging.INFO)\n",
    "        \n",
    "        #logging.basicConfig(format=\"%(levelname)s | %(asctime)s | %(message)s\")\n",
    "        \n",
    "        self.history_logger = logging.getLogger('history')\n",
    "        # stdout = logging.StreamHandler(stream=sys.stdout)\n",
    "        # stdout.setLevel(logging.INFO)\n",
    "        # self.history_logger.addHandler(stdout)\n",
    "        # self.history_logger.setLevel(logging.INFO)\n",
    "\n",
    "        memory_handler = MemoryHandler()\n",
    "        memory_handler.setLevel(logging.INFO)\n",
    "        formatter = JsonFormatter()\n",
    "        memory_handler.setFormatter(formatter)\n",
    "        self.history_logger.addHandler(memory_handler)\n",
    "        self.history_logger.setLevel(logging.INFO)\n",
    "        self.history_logger.propagate = False\n",
    "\n",
    "    def prob_map_random_initialization(self):\n",
    "        \"\"\"\n",
    "        Initializes the probability map randomly if no predefined map is provided.\n",
    "        \"\"\"\n",
    "        raw_probabilities = [random.random() for _ in range(self.n_tiles)]\n",
    "        total = sum(raw_probabilities)\n",
    "        self.prob_map = [prob / total for prob in raw_probabilities]\n",
    "\n",
    "\n",
    "    def sample_position(self, tile_loc: Optional[int] = None, old_position: Optional[Tuple[float, float]] = None) -> Tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Samples a uniform random position within a given tile for placing a UE.\n",
    "        \"\"\"\n",
    "        def random_offset() -> float:\n",
    "            \"\"\"Generates a random offset within the tile size.\"\"\"\n",
    "            return U(0, TILE_SIZE)\n",
    "\n",
    "        if tile_loc is not None:\n",
    "            row_index = tile_loc // self.num_tiles_x\n",
    "            col_index = tile_loc % self.num_tiles_x\n",
    "\n",
    "            tile_base_x = col_index * TILE_SIZE\n",
    "            tile_base_y = row_index * TILE_SIZE\n",
    "\n",
    "            new_position = (tile_base_x + random_offset(), tile_base_y + random_offset())\n",
    "        elif old_position is not None:\n",
    "            new_position = (old_position[0] + random_offset(), old_position[1] + random_offset())\n",
    "        else:\n",
    "            raise ValueError(\"Either tile_loc or old_position must be specified.\")\n",
    "\n",
    "        return new_position\n",
    "\n",
    "    def sample_ue(self):\n",
    "        \"\"\"\n",
    "        Randomly selects a UE from the controller's list of UEs.\n",
    "        \"\"\"\n",
    "        return np.random.choice(self.controller.UEs)\n",
    "        \n",
    "    def sample_tile(self, tile_loc: int= None):\n",
    "        \"\"\"\n",
    "        Samples a tile based on the probability map for new UE birth or based on a specific range for movement.\n",
    "        \"\"\"\n",
    "        if tile_loc is None:\n",
    "            ret = np.random.choice(range(self.n_tiles), p=self.prob_map)\n",
    "        else: #given a tile location, sample a new tile within the reachable tiles\n",
    "            low_bnd = max(0, tile_loc - UE_MAX_TILE_DISTANCE)\n",
    "            up_bnd = min(tile_loc + UE_MAX_TILE_DISTANCE, self.n_tiles - 1)\n",
    "            ret = np.random.randint(low_bnd,up_bnd)\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def generate_bs(self, filepath: str):\n",
    "        \"\"\"\n",
    "        Loads BS data from a CSV file and initializes BS objects within the controller.\n",
    "        \"\"\"\n",
    "        bs_df = pd.read_csv(filepath)\n",
    "        #self.controller.BSs = [BS(bs_id = bs_df.loc[i].id_station_anfr, position = (bs_df.loc[i].x,bs_df.loc[i].y))for i in bs_df.index] #position is in km from origin\n",
    "        self.controller.BSs = [BS(bs_id=row.id_station_anfr, position=(row.x, row.y), controller = self.controller) for _, row in bs_df.iterrows()]\n",
    "        self.controller.set_sectors()\n",
    "        #logging.info(f'Number of Base Stations: {len(self.controller.BSs)}')\n",
    "        #self.controller.BSs = self.controller.BSs[:300]\n",
    "        print('num_BSs: ', len(self.controller.BSs))\n",
    "    \n",
    "    #the first pool of user can be sampled using a Log Gaussian Cox process\n",
    "    def generate_UEs(self, max_cap_: int = None, verbose: bool = False):\n",
    "        \"\"\"\n",
    "        Generates an initial population of UEs based on a log-Gaussian Cox process.\n",
    "        \"\"\"\n",
    "        # Sample a Gaussian random variable for each tile\n",
    "        gaussian_samples = np.random.normal(MU_UE, SIGMA_UE, self.n_tiles)\n",
    "\n",
    "        # Calculate intensity and sample the number of UEs per tile\n",
    "        intensity = np.exp(gaussian_samples)\n",
    "        ue_counts = np.random.poisson(intensity)\n",
    "\n",
    "        # Generate UEs uniformly within each tile\n",
    "        users = []\n",
    "        ue_id = 1\n",
    "        ###\n",
    "        if max_cap_ is not None and max_cap_ <= self.n_tiles:\n",
    "            sampled_tiles = np.random.choice(self.n_tiles, max_cap_, replace=False)\n",
    "        else:\n",
    "            sampled_tiles = range(self.n_tiles)  # Use all tiles if max_cap_ is None or too large\n",
    "\n",
    "        if verbose: print(\"Sampled Tiles: \",sampled_tiles)\n",
    "\n",
    "        for tile_loc in sampled_tiles:\n",
    "            if verbose: \n",
    "                print(\"Tile: \",tile_loc)\n",
    "                print(\"Number of users to be generated: \", range(ue_counts[tile_loc]))\n",
    "            for _ in range(ue_counts[tile_loc]):\n",
    "                new_ue = UE(ue_id = ue_id, position = self.sample_position(tile_loc = tile_loc), tile = tile_loc)\n",
    "                users.append(new_ue)\n",
    "                ue_id += 1\n",
    "\n",
    "        if verbose: print(\"Generated UEs: \", len(users))     \n",
    "        # Select UEs based on Operator market share\n",
    "        selected_active_users = np.random.choice(users, int(len(users) * OPERATOR_MARKET_SHARE * ACTIVE_UE_FRACTION), replace=False)\n",
    "        # Set \"ACTIVE_UE_FRACTION\" of the selected UEs as active\n",
    "        for ue in selected_active_users: \n",
    "            ue.set_active()\n",
    "        self.controller.UEs =  selected_active_users\n",
    "        print('num_active_users: ', len(self.controller.UEs))\n",
    "    \n",
    "    def generate_random_ues(self, total_population: int, verbose: bool = False):\n",
    "        \"\"\"\n",
    "        Generates a random population of UEs distributed across tiles based on the self.prob_map.\n",
    "        Args:\n",
    "            total_population (int): The total number of UEs to generate.\n",
    "\n",
    "        This function will generate `total_population` UEs, distribute them across tiles based\n",
    "        on the probability map, and then place each UE at a random position within its assigned tile.\n",
    "        \"\"\"\n",
    "        # Sample the tiles for each UE based on the probability map\n",
    "        tiles = np.random.choice(range(self.n_tiles), size=total_population, p=self.prob_map)\n",
    "\n",
    "        # Generate UEs within their respective tiles\n",
    "        for tile in tiles:\n",
    "            # Sample a position within the tile\n",
    "            position = self.sample_position(tile_loc = tile)\n",
    "\n",
    "            # Create a new UE with a unique ID\n",
    "            ue_id = len(self.controller.UEs) + 1  # Unique ID for each UE\n",
    "            new_ue = UE(ue_id=ue_id, position=position, tile=tile)\n",
    "            if not self.controller.add_ue(ue = new_ue):\n",
    "                self.ue_death(ue= new_ue)\n",
    "\n",
    "        #if verbose:  # Assuming there is a verbose attribute for debug information\n",
    "        print('num_active_users: ', len(self.controller.UEs))\n",
    "\n",
    "    \n",
    "    def ue_arrival(self, time: float = None): #randomly placing inside the tile (tile_loc is the number of which tile inside the grid)\n",
    "        \"\"\"\n",
    "        Simulates the arrival of new UEs over time, integrating them into existing clusters.\n",
    "        \"\"\"\n",
    "        if time is not None:\n",
    "            yield self.env.timeout(time)\n",
    "\n",
    "        ue_id = self.controller.UEs[-1].ue_id + 1 if self.controller.UEs else 1\n",
    "        tile_loc = self.sample_tile()\n",
    "        new_ue = UE(ue_id = ue_id, position = self.sample_position(tile_loc = tile_loc), tile = tile_loc)\n",
    "        #new_ue.set_active()\n",
    "        if not self.controller.add_ue(ue = new_ue):  \n",
    "            yield self.env.process(self.ue_death(new_ue, 0))\n",
    "\n",
    "        c_ix = np.argmin(np.array([l2_norm(np.array(new_ue.position) - np.array(c.destination)) for c in self.clusters]))\n",
    "        self.clusters[c_ix].add_ue(ue = new_ue)\n",
    "        new_ue.cluster = self.clusters[c_ix].get_id()\n",
    "        # Add the user to the controller\n",
    "        #self.controller.add_ue(ue = new_ue) ##chose bs to pair based on snr level\n",
    "\n",
    "        # Schedule user death after a lifetime\n",
    "        lifetime = random.expovariate(self.mu)\n",
    "        self.env.process(self.ue_death(new_ue, lifetime))\n",
    "\n",
    "        # Schedule the next user arrival\n",
    "        inter_arrival_time = random.expovariate(self.lambda_)\n",
    "        self.env.process(self.ue_arrival(time = inter_arrival_time))\n",
    "\n",
    "    def ue_translation(self):\n",
    "        \"\"\"\n",
    "        The clusters movement happens accordint to an epsilon greedy strategy, then UEs moves following the cluster destination. \n",
    "        The BS handover function checks whether the displacement has exceeded the maximum coverage radius of the current base station, before triggering a new BS pairing.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            for c in self.clusters:\n",
    "                if random.random() < (1 - self.epsilon):\n",
    "                    c.move_destination()\n",
    "                    # Trigger user movement within the cluster\n",
    "                    for ue in c.paired_ues:\n",
    "                        ue.moving = True\n",
    "                        ##depending on the mobility_model used\n",
    "                        ue.position = self.sample_position(old_position= c.destination)\n",
    "                        #ue.move() #if the displacement is above a given threshold, the handover will be triggered\n",
    "                        if not self.controller.bs_handover(ue = ue):\n",
    "                            yield self.env.process(self.ue_death(ue, 0))\n",
    "\n",
    "            yield self.env.timeout(self.move_interval)\n",
    "\n",
    "\n",
    "    def metrics_collection(self):\n",
    "        \"\"\"\n",
    "        Periodically collects SINR metrics across all BS-UE pairs in the simulation.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            sinr_metrics = self.controller.gather_metrics()\n",
    "            #self.controller.optimize_power()\n",
    "            self.history_logger.info({\n",
    "                'time': self.env.now,\n",
    "                **sinr_metrics  # add also hyper-params\n",
    "            })\n",
    "            yield self.env.timeout(self.tau)\n",
    "\n",
    "    def ue_death(self, ue: UE, lifetime: float = None):\n",
    "        \"\"\"\n",
    "        Simulates the departure of a UE after its lifetime expires.\n",
    "        \"\"\"\n",
    "        if lifetime is not None:\n",
    "            yield self.env.timeout(lifetime)\n",
    "        if ue.active:\n",
    "            cluster = self.controller._lookup(self.clusters, ue.cluster)\n",
    "            cluster.remove_ue(ue_id=ue.ue_id)\n",
    "            self.controller.kill_ue(ue)\n",
    "        \n",
    "    # def ue_translation(self,ue: UE):\n",
    "    #     #change coordinates of UE\n",
    "    #     #trigger controller handover\n",
    "    #     #ue can move up to MaxDistance tiles from the current tile\n",
    "    #     ue.moving = True\n",
    "    #     low_bnd = ue.tile-UE_MAX_TILE_DISTANCE if ue.tile>UE_MAX_TILE_DISTANCE else ue.tile-ue.tile \n",
    "    #     up_bnd = ue.tile+UE_MAX_TILE_DISTANCE\n",
    "    #     new_tile_loc = np.random.randint(low_bnd,up_bnd)\n",
    "    #     ue.position = self.sample_position(tile_loc = new_tile_loc)\n",
    "    #     self.controller.bs_handover(ue = ue) #pair with the new bs in the new location\n",
    "\n",
    "    def cluster_UEs(self, n_clusters):\n",
    "        \"\"\"\n",
    "        Cluster UEs based on their spatial positions using K-means clustering.\n",
    "        \n",
    "        Parameters:\n",
    "            users (list of UE): List of user equipment (UE) objects.\n",
    "            n_clusters (int): Number of clusters to create.\n",
    "        \n",
    "        Returns:\n",
    "            list of Cluster: List of Cluster objects with UEs grouped.\n",
    "        \"\"\"\n",
    "        # Extract user positions from UE objects\n",
    "        users = self.controller.UEs\n",
    "        user_positions = np.array([ue.position for ue in users])\n",
    "\n",
    "        # Apply K-means clustering\n",
    "        kmeans = KMeans(n_clusters=n_clusters, n_init='auto').fit(user_positions)\n",
    "\n",
    "        # Create Cluster objects based on the number of clusters\n",
    "        self.clusters = [Cluster(id = i) for i in range(n_clusters)]\n",
    "        #clusters = [Cluster(id = i) for i in range(len(np.unique(kmeans.labels_)))]\n",
    "        \n",
    "        for i,cluster in enumerate(self.clusters):\n",
    "            cluster.resample_params()\n",
    "            cluster.set_first_destination(position= kmeans.cluster_centers_[i])\n",
    "\n",
    "        # Assign cluster labels to UEs and add them to their corresponding Cluster\n",
    "        for ue, label in zip(users, kmeans.labels_):\n",
    "            ue.cluster = label\n",
    "            self.clusters[label].add_ue(ue)\n",
    "    \n",
    "    def write_log(self):\n",
    "        # Ensure output directory exists\n",
    "        os.makedirs('output', exist_ok=True)\n",
    "        with open(f'output/simulation_logs_sim{self.id}.json', 'w') as log_file:\n",
    "            for record in self.history_logger.handlers[0].records:\n",
    "                log_file.write(record + '\\n')\n",
    "\n",
    "    def initialize(self):\n",
    "        pass\n",
    "\n",
    "    def run(self, filepath: str, max_cap_: int = None, verbose: bool = False, n_clusters: int = 5, separate_plots: bool = True , gif_toggle: bool = False, alpha_fairness: float = 1.0): #update description\n",
    "        \"\"\"\n",
    "        Runs the entire simulation setup, managing UE births, movements, and SINR collection.\n",
    "        \"\"\"\n",
    "\n",
    "        print('network_area: ', round(NET_WIDTH*NET_HEIGHT,3), 'km^2')\n",
    "        print('n_tiles: ', self.n_tiles)\n",
    "\n",
    "        self.controller.alpha_fairness = alpha_fairness\n",
    "\n",
    "        #Populate the network with base stations\n",
    "        self.generate_bs(filepath)\n",
    "\n",
    "        # Intial static user population of the network\n",
    "        #self.generate_UEs(max_cap_=max_cap_, verbose=verbose)\n",
    "        self.generate_random_ues(total_population=max_cap_)\n",
    "\n",
    "        # #plot the network\n",
    "        # self.plot_net()\n",
    "\n",
    "        # # Build the UEs database\n",
    "        # self.controller.build_ues_db(filename= \"ues_set.csv\")\n",
    "\n",
    "        #cluster the UES\n",
    "        self.cluster_UEs(n_clusters)\n",
    "        #self.cluster_UEs(k_means_cluster) #hparam\n",
    "        self.controller.build_ues_db(filename=f'output/initial_ues_sim{self.id}.csv')\n",
    "        # Start the birt-death process\n",
    "        self.env.process(self.ue_arrival())\n",
    "\n",
    "        # Start the cluster movement process\n",
    "        self.env.process(self.ue_translation())\n",
    "\n",
    "        # Start the SINR collection process\n",
    "        self.env.process(self.metrics_collection())\n",
    "\n",
    "        for t in tqdm(range(SIM_TIME)):\n",
    "            self.env.step()\n",
    "\n",
    "        self.controller.build_ues_db(filename=f'output/final_ues_sim{self.id}.csv')\n",
    "        self.plot_net2D()\n",
    "        self.plot_metrics_history(separate_plots=separate_plots)\n",
    "        self.write_log()\n",
    "            # if gif_toggle:\n",
    "            #     map_update_ue_positions(map_obj, self.controller.UEs)  # Update UEs on the map\n",
    "            #     filename = f\"snapshot_{t}.html\"\n",
    "            #     save_map_state(map_obj, filename)\n",
    "\n",
    "        # if gif_toggle:\n",
    "        #     draw_cluster_trajectories(map_obj, clusters)  # Update trajectories on the map\n",
    "        #     create_gif('path_to_snapshots_folder', 'simulation.gif', duration=1)\n",
    "\n",
    "        # Run the SimPy event loop\n",
    "        \n",
    "\n",
    "        #to model the time \n",
    "        \n",
    "        #poisson process to spwan and to kill users\n",
    "        \n",
    "        # Start the first user arrival\n",
    "        \n",
    "\n",
    "\n",
    "        #simulate timeline\n",
    "        # T = 100 #s\n",
    "        # ues_pool = generate_user(n_users, prob_map, grid) #==>return of class UEs \n",
    "        # generate_ues_clusters(n_clusters) #==> pair each user with a label indicating the cluster,\n",
    "        # generate_cluster_params(n_clusters) #==> return a dict: key cluster_id, parameters for each cluster\n",
    "        # for t in range(T):\n",
    "        #     for c in clusters:\n",
    "        #         for ue in c.paired_ues:\n",
    "        #             ue.move()\n",
    "        #         c.move_destination()\n",
    "\n",
    "        #     if t%T_SAMPLE == 0:\n",
    "        #         compute_analytics()\n",
    "        #         update_log()\n",
    "\n",
    "        # print_log()\n",
    "        # plot_simulation2D()\n",
    "\n",
    "        # if graphics:\n",
    "        #     plot_simulation3D()\n",
    "\n",
    "\n",
    "    \n",
    "    def plot_net2D(self):\n",
    "        \"\"\"\n",
    "        Visualizes the 2D layout of the network, including UEs, BSs, and clusters.\n",
    "        \"\"\"\n",
    "\n",
    "        bss_net = self.controller.BSs\n",
    "        ues_net = self.controller.UEs\n",
    "        km_to_m = 1000\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        # Plot end-users and base stations\n",
    "        ue_x_positions = [ue.position[0]*km_to_m for ue in ues_net]\n",
    "        ue_y_positions = [ue.position[1]*km_to_m for ue in ues_net]\n",
    "        \n",
    "        ax.scatter(ue_x_positions, ue_y_positions, marker='.', c='gray', alpha=0.75, s=1, label='End-user')\n",
    "\n",
    "        bs_x_positions = [bs.position[0]*km_to_m for bs in bss_net]\n",
    "        bs_y_positions = [bs.position[1]*km_to_m for bs in bss_net]\n",
    "\n",
    "        ax.scatter(bs_x_positions, bs_y_positions, marker='^', c='orange',s=10, label='Base Station')\n",
    "\n",
    "        # Draw a square region of interest\n",
    "        #ax.add_patch(plt.Rectangle((1500, 1500), 2000, 2000, fill=False, edgecolor='blue', linewidth=2))\n",
    "\n",
    "        # Draw the boundary of the whole area\n",
    "        #ax.add_patch(plt.Rectangle((0, 0), 5000, 5000, fill=False, edgecolor='red', linewidth=2))\n",
    "\n",
    "        # Plot each cluster's trajectory\n",
    "        for cluster in self.clusters:\n",
    "            # Ensure that the cluster has a non-empty history to plot\n",
    "            if hasattr(cluster, 'history') and cluster.history:\n",
    "                x_positions = [pos[0] * km_to_m for pos in cluster.history]\n",
    "                y_positions = [pos[1] * km_to_m for pos in cluster.history]\n",
    "                ax.plot(x_positions, y_positions, marker='', linestyle='-', alpha=0.5, label=f'Cluster {cluster.id}')\n",
    "\n",
    "        # Labeling the axes\n",
    "        ax.set_xlabel('Distance (m)')\n",
    "        ax.set_ylabel('Distance (m)')\n",
    "\n",
    "        # Set the plot limits\n",
    "        ax.set_xlim(0, NET_WIDTH*km_to_m)\n",
    "        ax.set_ylim(0, NET_HEIGHT*km_to_m)\n",
    "\n",
    "        # Add a legend\n",
    "        ax.legend(loc = 'upper right')\n",
    "\n",
    "        #save the plot as png image in the folder output\n",
    "        plt.savefig(f'output/2D_network_sim{self.id}.png')\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    # def plot_metrics_history(self):\n",
    "    #     \"\"\"\n",
    "    #     Plot the history of collected metrics over time.\n",
    "    #     This function visualizes metrics such as SINR over the course of the simulation.\n",
    "    #     \"\"\"\n",
    "    #     times, metrics = zip(*[(log['time'], log['sinr']) for log in self.history_logger.handlers[0].records])\n",
    "    #     plt.figure(figsize=(10, 5))\n",
    "    #     for idx, metric_snapshot in enumerate(metrics):\n",
    "    #         plt.plot(times, metric_snapshot, label=f'Metric at {idx}')\n",
    "    #     plt.xlabel('Simulation Time')\n",
    "    #     plt.ylabel('Metrics Value')\n",
    "    #     plt.title('Metrics Over Time')\n",
    "    #     plt.legend()\n",
    "    #     plt.show()\n",
    "\n",
    "    # def plot_metrics_history(self, separate_plots=True):\n",
    "    #     \"\"\"\n",
    "    #     Plot the history of collected metrics over time.\n",
    "    #     This function visualizes various metrics collected during the simulation. It can generate either a single plot with all metrics or separate plots for each metric.\n",
    "\n",
    "    #     Args:\n",
    "    #     separate_plots (bool): If True, generate separate plots for each metric.\n",
    "    #     \"\"\"\n",
    "    #     # Check if there is data to plot\n",
    "    #     if not self.history_logger.handlers[0].records:\n",
    "    #         print(\"No data to plot.\")\n",
    "    #         return\n",
    "\n",
    "    #     # Gather times and all metrics from the records\n",
    "    #     times = [log['time'] for log in self.history_logger.handlers[0].records]\n",
    "    #     metric_keys = set(key for log in self.history_logger.handlers[0].records for key in log.keys() if key != 'time')\n",
    "    #     hyper_params = [key for key in metric_keys if '_hyper_param' in key]\n",
    "    #     metrics_to_plot = [key for key in metric_keys if '_hyper_param' not in key]\n",
    "\n",
    "    #     if separate_plots:\n",
    "    #         # Plot each metric on a separate figure\n",
    "    #         for metric in metrics_to_plot:\n",
    "    #             plt.figure(figsize=(10, 5))\n",
    "    #             metric_values = [log[metric] for log in self.history_logger.handlers[0].records]\n",
    "    #             plt.plot(times, metric_values, label=f'{metric.capitalize()}')\n",
    "    #             hyper_param_values = ', '.join([key.split('_hyper_param')[0].capitalize() for key in hyper_params])\n",
    "    #             plt.xlabel('Simulation Time')\n",
    "    #             plt.ylabel('Metric Values')\n",
    "    #             plt.title(f'{metric.capitalize()} Over Time')\n",
    "    #             if hyper_param_values:\n",
    "    #                 plt.legend([f'{metric.capitalize()} ({hyper_param_values})'])\n",
    "    #             else:\n",
    "    #                 plt.legend()\n",
    "    #             plt.show()\n",
    "    #     else:\n",
    "    #         # Plot all metrics on one figure\n",
    "    #         plt.figure(figsize=(10, 5))\n",
    "    #         for metric in metrics_to_plot:\n",
    "    #             metric_values = [log[metric] for log in self.history_logger.handlers[0].records]\n",
    "    #             plt.plot(times, metric_values, label=f'{metric.capitalize()}')\n",
    "    #         hyper_param_values = ', '.join([key.split('_hyper_param')[0].capitalize() for key in hyper_params])\n",
    "    #         plt.xlabel('Simulation Time')\n",
    "    #         plt.ylabel('Metric Values')\n",
    "    #         plt.title('Metrics Over Time')\n",
    "    #         if hyper_param_values:\n",
    "    #             plt.legend([f'{metric.capitalize()} ({hyper_param_values})' for metric in metrics_to_plot])\n",
    "    #         else:\n",
    "    #             plt.legend()\n",
    "    #         plt.show()\n",
    "\n",
    "    def plot_metrics_history(self, separate_plots=True):\n",
    "        handler = self.history_logger.handlers[0]\n",
    "        if not hasattr(handler, 'records') or not handler.records:\n",
    "            print(\"No data to plot.\")\n",
    "            return\n",
    "\n",
    "        # Parse records assuming they are in JSON format\n",
    "        records = [json.loads(record) for record in handler.records]  # Adjusting how records are parsed\n",
    "        times = [log['time'] for log in records]\n",
    "        metric_keys = {key for log in records for key in log if key != 'time'}\n",
    "\n",
    "        if separate_plots:\n",
    "            for metric in metric_keys:\n",
    "                plt.figure(figsize=(10, 5))\n",
    "                metric_values = [log[metric] for log in records if metric in log]  # Safety check for key existence\n",
    "                plt.plot(times, metric_values, label=f'{metric.capitalize()}')\n",
    "                plt.xlabel('Time (s)')\n",
    "                plt.ylabel('Metric Values')\n",
    "                plt.title(f'{metric.capitalize()} Over Time')\n",
    "                plt.legend()\n",
    "                plt.savefig(f'output/{metric}_sim{self.id}.png')\n",
    "                plt.show()\n",
    "        else:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            for metric in metric_keys:\n",
    "                metric_values = [log[metric] for log in records if metric in log]  # Safety check for key existence\n",
    "                plt.plot(times, metric_values, label=f'{metric.capitalize()}')\n",
    "            plt.xlabel('Time (s)')\n",
    "            plt.ylabel('Metric Values')\n",
    "            plt.title('Metrics Over Time')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'output/metrics_sim{self.id}.png')\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIM_TIME = 500\n",
    "n_clusters = 5\n",
    "cntr = Controller()\n",
    "sim = SIMULATION(cntr)\n",
    "sim.run(id= 1, filepath = \"datasets/Filtered_4G_Sites_Orange_Paris.csv\",n_clusters=n_clusters, max_cap_= 600, verbose = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
